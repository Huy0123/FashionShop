/**
 * Smart AI Router - T·ª± ƒë·ªông ch·ªçn AI ph√π h·ª£p
 * @author Chevai AI Team
 */

import { processMessage } from './aiCore.js';
import { generateGeminiAI, shouldGeminiRespond } from './aiServiceGemini.js';
import { learningService } from './learningService.js';

class SmartAI {
   constructor() {
      this.geminiUsage = 0;
      this.lastReset = new Date().toDateString();
      this.GEMINI_LIMIT = 1400; // Daily limit
   }
   
   // Main AI function - t·ª± ƒë·ªông ch·ªçn AI t·ªët nh·∫•t
   async chat(message, userId = null, roomId = null) {
      try {
         console.log(`ü§ñ Smart AI processing: "${message}"`);
         
         // 1. Ki·ªÉm tra personalized response tr∆∞·ªõc
         if (userId) {
            const personalizedResponse = await learningService.getPersonalizedResponse(userId, message);
            if (personalizedResponse) {
               console.log(`üéØ Using personalized response for user ${userId}`);
               return personalizedResponse;
            }
         }
         
         // 2. Ki·ªÉm tra context tr∆∞·ªõc khi analyze complexity
         const { getConversationContext } = await import('./conversationContext.js');
         const context = getConversationContext(roomId);
         const hasActiveContext = context && (context.lastAction === 'asked_for_image' || context.lastAction === 'mentioned_product');
         
         // 3. Ph√¢n t√≠ch complexity
         const analysis = this.analyzeComplexity(message, hasActiveContext);
         console.log(`üìä Complexity analysis:`, analysis);
         
         // 4. Check quota
         this.checkQuotaReset();
         const canUseGemini = this.geminiUsage < this.GEMINI_LIMIT;
         
         // 5. Ch·ªçn AI th√¥ng minh h∆°n - IMPROVED LOGIC
         let useGemini = false;
         let reason = '';
         
         if (!canUseGemini) {
            reason = `Gemini quota exceeded (${this.geminiUsage}/${this.GEMINI_LIMIT}) - using Core AI`;
         } else if (hasActiveContext && /(c√≥|ok|yes|ƒë∆∞·ª£c|·ª´|ƒë·ªìng\s*√Ω|xem|show)/i.test(message.trim())) {
            // IMPORTANT: If user is responding to a Gemini context (like confirming to see image), continue with Gemini
            useGemini = true;
            reason = 'Continuing Gemini conversation context';
         } else if (analysis.isSimple && analysis.confidence > 0.8 && !hasActiveContext) {
            reason = 'Simple query - Core AI is sufficient';
         } else if (analysis.isComplex || shouldGeminiRespond(message)) {
            useGemini = true;
            reason = 'Complex query requires Gemini AI';
         } else if (analysis.isMedium && analysis.needsPersonalization) {
            useGemini = true;
            reason = 'Personalized response needed - using Gemini AI';
         } else if (analysis.needsContext) {
            useGemini = true;
            reason = 'Context-aware response needed - using Gemini AI';
         } else {
            reason = 'Standard query - using Core AI';
         }
         
         console.log(`üéØ AI Decision: ${useGemini ? 'GEMINI' : 'CORE'} - ${reason}`);
         
         // 6. Generate response
         let response;
         let aiProvider;
         
         if (useGemini) {
            try {
               response = await generateGeminiAI(message, roomId);
               this.geminiUsage++;
               aiProvider = 'Gemini AI';
               console.log(`‚úÖ Gemini used (${this.geminiUsage}/${this.GEMINI_LIMIT})`);
            } catch (error) {
               console.log(`‚ö†Ô∏è Gemini failed, using Core AI: ${error.message}`);
               response = await processMessage(message, userId);
               aiProvider = 'Core AI (Gemini fallback)';
            }
         } else {
            response = await processMessage(message, userId);
            aiProvider = 'Core AI';
         }
         
         // 7. Add metadata
         if (typeof response === 'string') {
            response = { message: response };
         }
         response.aiProvider = aiProvider;
         response.reason = reason;
         
         return response;
         
      } catch (error) {
         console.error('üö® Smart AI Error:', error);
         return {
            message: "Xin l·ªói, m√¨nh g·∫∑p s·ª± c·ªë! Th·ª≠ l·∫°i nh√© üòÖ",
            aiProvider: 'Error Fallback',
            reason: error.message
         };
      }
   }
   
   // Ph√¢n t√≠ch ƒë·ªô ph·ª©c t·∫°p c·ªßa message
   analyzeComplexity(message, hasActiveContext = false) {
      const trimmed = message.trim();
      const wordCount = trimmed.split(/\s+/).length;
      
      // Simple patterns - queries ƒë∆°n gi·∫£n
      const simplePatterns = [
         /^(ch√†o|hello|hi|xin ch√†o)$/i,
         /^(c·∫£m ∆°n|thank you|thanks)$/i,
         /^(bye|t·∫°m bi·ªát|goodbye)$/i,
         /^(gi√°|price)\?*$/i,
         /^(size|k√≠ch th∆∞·ªõc)\?*$/i
      ];
      
      // UPDATED: Don't treat confirmation as simple if there's active context
      if (!hasActiveContext) {
         simplePatterns.push(/^(c√≥|ok|yes|ƒë∆∞·ª£c|·ª´)$/i);
      }
      
      // Complex patterns - c·∫ßn AI th√¥ng minh h∆°n
      const complexPatterns = [
         /\?.*\?/i, // Multiple questions
         /(t∆∞ v·∫•n|advice|suggest|g·ª£i √Ω|recommend)/i,
         /(so s√°nh|compare|kh√°c nhau|difference)/i,
         /(ph·ªëi ƒë·ªì|outfit|style|fashion|mix\s*&\s*match)/i,
         /(trend|xu h∆∞·ªõng|m·ªõi nh·∫•t|hot|trendy)/i,
         /(cho.*xem|mu·ªën xem|xem.*ƒëi|show.*me)/i, // View requests
         /(ƒëi\s*ch∆°i|ƒëi\s*l√†m|ƒëi\s*h·ªçc|occasion)/i, // Context-based requests
         /(\d+\s*kg|c√¢n\s*n·∫∑ng|weight|size.*n√†o|v·ª´a.*kh√¥ng|fit.*kh√¥ng|m·∫∑c.*c√≥|ƒëi.*ƒë∆∞·ª£c|ph√π\s*h·ª£p)/i, // Size consultation - ENHANCED
         /(√°o.*qu·∫ßn|qu·∫ßn.*√°o|outfit|set)/i, // Combination requests
         /(ƒë·∫πp.*kh√¥ng|th·∫ø\s*n√†o|how.*look)/i // Opinion requests
      ];
      
      // Medium complexity patterns
      const mediumPatterns = [
         /(gi√°.*bao\s*nhi·ªÅu|how\s*much)/i,
         /(c√≥.*m√†u|color.*available)/i,
         /(size.*n√†o|what\s*size)/i,
         /(ch·∫•t\s*li·ªáu|material|fabric)/i
      ];
      
      const isSimple = simplePatterns.some(pattern => pattern.test(trimmed)) && wordCount <= 5;
      const isComplex = complexPatterns.some(pattern => pattern.test(trimmed)) || wordCount > 10 || hasActiveContext;
      const isMedium = mediumPatterns.some(pattern => pattern.test(trimmed)) && !isSimple && !isComplex;
      
      let confidence = 0.5;
      if (isSimple) confidence = 0.9;
      else if (isComplex) confidence = 0.85;
      else if (isMedium) confidence = 0.7;
      
      return {
         isSimple,
         isComplex,
         isMedium,
         wordCount,
         confidence,
         needsPersonalization: /(t√¥i|m√¨nh|em|b·∫°n)/i.test(trimmed),
         needsContext: /(ƒëi\s*ch∆°i|ƒëi\s*l√†m|occasion|\d+\s*kg|c√¢n\s*n·∫∑ng|size.*n√†o|v·ª´a.*kh√¥ng|fit.*kh√¥ng|m·∫∑c.*c√≥)/i.test(trimmed) || hasActiveContext
      };
   }
   
   // Check v√† reset quota
   checkQuotaReset() {
      const today = new Date().toDateString();
      if (this.lastReset !== today) {
         this.geminiUsage = 0;
         this.lastReset = today;
         console.log('üìä Daily quota reset');
      }
   }
   
   // Nh·∫≠n feedback t·ª´ user
   async receiveFeedback(userId, rating, roomId = null) {
      if (userId) {
         await learningService.receiveFeedback(userId, rating);
         console.log(`‚≠ê Received feedback: ${rating}/5 from user ${userId}`);
      }
   }
   
   // L·∫•y stats
   getStats() {
      return {
         geminiUsage: this.geminiUsage,
         geminiLimit: this.GEMINI_LIMIT,
         quotaRemaining: this.GEMINI_LIMIT - this.geminiUsage,
         lastReset: this.lastReset,
         provider: 'Smart AI Router'
      };
   }
   
   // L·∫•y user learning stats
   async getUserStats(userId) {
      return await learningService.getLearningStats(userId);
   }
}

// Export singleton instance
export const smartAI = new SmartAI();
